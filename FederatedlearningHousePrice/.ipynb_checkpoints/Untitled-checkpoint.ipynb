{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a4b7b2-9b19-480a-a9d0-774101556435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"Train_Data.csv\")\n",
    "test_data = pd.read_csv(\"Test_Data.csv\")\n",
    "# Checking the column names\n",
    "print(train_data.columns)\n",
    "\n",
    "# Calculate total cost\n",
    "train_data[\"total cost\"] = (train_data[\"unit price of residence space\"] * train_data[\"residence space\"] + train_data[\"unit price of building space\"] * train_data[\"building space\"]) * train_data[\"exchange rate\"]\n",
    "\n",
    "# Round the total cost to the nearest integer\n",
    "train_data[\"total cost\"] = train_data[\"total cost\"].round()\n",
    "\n",
    "# Dropping the columns \"Unit price of residence space\" and \"Unit price of building space\"\n",
    "train_data = train_data.drop([\"unit price of residence space\", \"unit price of building space\"], axis=1)\n",
    "import numpy as np\n",
    "\n",
    "# Define the price ranges based on the total cost column\n",
    "price_ranges = [(0, 300000), (300000, 500000), (500000, 700000), (700000, float('inf'))]\n",
    "\n",
    "# Define a function to assign each total cost to a price range\n",
    "def assign_price_range(total_cost):\n",
    "    for i in range(len(price_ranges)):\n",
    "        if total_cost >= price_ranges[i][0] and total_cost < price_ranges[i][1]:\n",
    "            return i + 1\n",
    "\n",
    "# Create a new column in the train dataset to store the price ranges\n",
    "train_data['price range'] = train_data['total cost'].apply(assign_price_range)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Combine the training and test datasets\n",
    "combined_data = pd.concat([train_data, test_data])\n",
    "\n",
    "# Fit the label encoder on the combined dataset\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(combined_data['district'])\n",
    "\n",
    "# Apply the label encoder to the district column of both datasets\n",
    "train_data['district'] = encoder.transform(train_data['district'])\n",
    "test_data['district'] = encoder.transform(test_data['district'])\n",
    "\n",
    "# Repeat the process for the city column\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(combined_data['city'])\n",
    "\n",
    "train_data['city'] = encoder.transform(train_data['city'])\n",
    "test_data['city'] = encoder.transform(test_data['city'])\n",
    "\n",
    "# Repeat the process for the zip code column\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(combined_data['zip code'])\n",
    "\n",
    "train_data['zip code'] = encoder.transform(train_data['zip code'])\n",
    "test_data['zip code'] = encoder.transform(test_data['zip code'])\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the train dataset into train and validation datasets\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "# Define the features and target\n",
    "features = ['number of rooms', 'security level of the community', 'residence space', 'building space', 'noise level', 'waterfront', 'view', 'air quality level', 'aboveground space ', 'basement space', 'building year', 'decoration year', 'district', 'city', 'zip code']\n",
    "target = 'price range'\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the train_data into four parts for the clients\n",
    "client_data = np.array_split(train_data, 4)\n",
    "\n",
    "# Define the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=20, random_state=42)\n",
    "\n",
    "# Define a function to train the model on each client's data\n",
    "def train_client_model(client_data):\n",
    "    X = client_data[features]\n",
    "    y = client_data[target]\n",
    "    rf_model.fit(X, y)\n",
    "\n",
    "# Train the model on each client's data\n",
    "for client in client_data:\n",
    "    train_client_model(client)\n",
    "\n",
    "# Define a function to aggregate the model weights from each client\n",
    "def aggregate_model_weights(client_models):\n",
    "    avg_model_weights = []\n",
    "    for weights_list in zip(*client_models):\n",
    "        avg_weights = np.mean([tree.feature_importances_ for tree in weights_list], axis=0)\n",
    "        avg_model_weights.append(avg_weights)\n",
    "    return avg_model_weights\n",
    "\n",
    "# Define a function to evaluate the model on the validation data\n",
    "def evaluate_model(model, val_data):\n",
    "    X_val = val_data[features]\n",
    "    y_val = val_data[target]\n",
    "    y_pred = model.predict(X_val)\n",
    "    return accuracy_score(y_val, y_pred)\n",
    "\n",
    "# Define the initial global model as the trained model on the first client's data\n",
    "global_model = rf_model\n",
    "\n",
    "# Define the number of federated learning rounds\n",
    "num_rounds = 10\n",
    "\n",
    "# Perform federated learning\n",
    "for i in range(num_rounds):\n",
    "    print(\"Round:\", i+1)\n",
    "    client_models = []\n",
    "    for client in client_data:\n",
    "        client_model = RandomForestClassifier(n_estimators=100, max_depth=20, random_state=42)\n",
    "        X = client[features]\n",
    "        y = client[target]\n",
    "        client_model.fit(X, y)\n",
    "        client_models.append(client_model)\n",
    "    avg_model_weights = aggregate_model_weights([model.estimators_ for model in client_models])\n",
    "    global_model.estimators_ = avg_model_weights\n",
    "    accuracy = evaluate_model(global_model, val_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
